{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T28mbw3aEyDu"
      },
      "source": [
        "https://qiita.com/seri28/items/0b19e1c3e1cc584f71a4\n",
        "\n",
        "https://qiita.com/jun40vn/items/d8a1f71fae680589e05c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU1Bfm9jh3GT"
      },
      "source": [
        "### マウント"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFQ-JF5_m6W",
        "outputId": "da40fcf7-f83d-4a14-af60-c6eca48c9988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  # google.colabモジュールからdriveをインポート\n",
        "\n",
        "drive.mount(\"/content/drive\")  # Google Driveをマウントする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HFZZ7hMAG1Q"
      },
      "source": [
        "### モジュールインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OAU5Lx21AFtp"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame, Series\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7d9bE-lATaL"
      },
      "source": [
        "### ファイル読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wAJQCtYZAORR"
      },
      "outputs": [],
      "source": [
        "path = \"drive/My Drive/Colab Notebooks/Titanic/\"\n",
        "\n",
        "df_train = pd.read_csv(path + \"train.csv\")\n",
        "df_test = pd.read_csv(path + \"test.csv\")\n",
        "### おまじない\n",
        "df_train['Survived'] = np.where(df_train['Survived'] == 1, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dYqyb-PdRKY"
      },
      "source": [
        "### 合成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cgO_QSyqdQj2"
      },
      "outputs": [],
      "source": [
        "df_train_len = len(df_train)\n",
        "df = pd.concat([df_train, df_test], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL0YZQ6LCbt0"
      },
      "source": [
        "### 特徴量エンジニアリング"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kmhwpw7JCNTc"
      },
      "outputs": [],
      "source": [
        "# Name\n",
        "df[\"Title\"] = df[\"Name\"].map(lambda x: x.split(\", \")[1].split(\". \")[0])\n",
        "df[\"Title\"].replace([\"Mme\", \"Ms\"], \"Mrs\", inplace=True)\n",
        "df[\"Title\"].replace([\"Mlle\"], \"Miss\", inplace=True)\n",
        "df[\"Title\"].replace(\n",
        "    [\n",
        "        \"Capt\",\n",
        "        \"Col\",\n",
        "        \"Major\",\n",
        "        \"Dr\",\n",
        "        \"Rev\",\n",
        "        \"Don\",\n",
        "        \"Sir\",\n",
        "        \"the Countess\",\n",
        "        \"Lady\",\n",
        "        \"Dona\",\n",
        "        \"Jonkheer\",\n",
        "    ],\n",
        "    \"Rare\",\n",
        "    inplace=True,\n",
        ")\n",
        "\n",
        "df_train[\"Surname\"] = df_train[\"Name\"].map(lambda name: name.split(\",\")[0].strip())\n",
        "df[\"Surname\"] = df[\"Name\"].map(lambda name: name.split(\",\")[0].strip())\n",
        "df_train[\"FamilyGroup\"] = df_train[\"Surname\"].map(df[\"Surname\"].value_counts())\n",
        "Female_Child_Group = df_train.loc[\n",
        "    (df_train[\"FamilyGroup\"] >= 2)\n",
        "    & ((df_train[\"Age\"] <= 16) | (df_train[\"Sex\"] == \"female\"))\n",
        "]\n",
        "Female_Child_Group = Female_Child_Group.groupby(\"Surname\")[\"Survived\"].mean()\n",
        "Male_Adult_Group = df_train.loc[\n",
        "    (df_train[\"FamilyGroup\"] >= 2)\n",
        "    & (df_train[\"Age\"] > 16)\n",
        "    & (df_train[\"Sex\"] == \"male\")\n",
        "]\n",
        "Male_Adult_List = Male_Adult_Group.groupby(\"Surname\")[\"Survived\"].mean()\n",
        "\n",
        "Dead_list = set(\n",
        "    Female_Child_Group[Female_Child_Group.apply(lambda x: x == 1)].index\n",
        ") | set(Male_Adult_List[Male_Adult_List.apply(lambda x: x == 1)].index)\n",
        "Survived_list = set(\n",
        "    Female_Child_Group[Female_Child_Group.apply(lambda x: x == 0)].index\n",
        ") | set(Male_Adult_List[Male_Adult_List.apply(lambda x: x == 0)].index)\n",
        "\n",
        "df[\"Dead_list\"] = 0\n",
        "df[\"Survived_list\"] = 0\n",
        "\n",
        "df.loc[df[\"Surname\"].isin(Dead_list), \"Dead_list\"] = 1\n",
        "df.loc[df[\"Surname\"].isin(Survived_list), \"Survived_list\"] = 1\n",
        "\n",
        "df[\"Last_name\"] = df[\"Name\"].apply(lambda x: x.split(\",\")[0])\n",
        "\n",
        "# Name & Title\n",
        "df[\"Family_survival\"] = 0.5\n",
        "for grp, grp_df in df.groupby([\"Last_name\", \"Fare\"]):\n",
        "\n",
        "    if len(grp_df) != 1:\n",
        "        for index, row in grp_df.iterrows():\n",
        "            smax = grp_df.drop(index)[\"Survived\"].max()\n",
        "            smin = grp_df.drop(index)[\"Survived\"].min()\n",
        "            passID = row[\"PassengerId\"]\n",
        "\n",
        "            if smax == 1.0:\n",
        "                df.loc[df[\"PassengerId\"] == passID, \"Family_survival\"] = 1\n",
        "            elif smin == 0.0:\n",
        "                df.loc[df[\"PassengerId\"] == passID, \"Family_survival\"] = 0\n",
        "for grp, grp_df in df.groupby(\"Ticket\"):\n",
        "    if len(grp_df) != 1:\n",
        "        for ind, row in grp_df.iterrows():\n",
        "            if (row[\"Family_survival\"] == 0) | (row[\"Family_survival\"] == 0.5):\n",
        "                smax = grp_df.drop(ind)[\"Survived\"].max()\n",
        "                smin = grp_df.drop(ind)[\"Survived\"].min()\n",
        "                passID = row[\"PassengerId\"]\n",
        "                if smax == 1.0:\n",
        "                    df.loc[df[\"PassengerId\"] == passID, \"Family_survival\"] = 1\n",
        "                elif smin == 0.0:\n",
        "                    df.loc[df[\"PassengerId\"] == passID, \"Family_survival\"] = 0\n",
        "\n",
        "\n",
        "# Ticket\n",
        "num_ticket = df[df[\"Ticket\"].str.match(\"[0-9]+\")].copy()\n",
        "num_ticket_index = num_ticket.index.values.tolist()\n",
        "num_alpha_ticket = df.drop(num_ticket_index).copy()\n",
        "\n",
        "num_ticket[\"Ticket\"] = num_ticket[\"Ticket\"].apply(lambda x: int(x))\n",
        "num_ticket[\"Ticket_cat\"] = 0\n",
        "num_ticket.loc[\n",
        "    (num_ticket[\"Ticket\"] >= 100000) & (num_ticket[\"Ticket\"] < 200000), \"Ticket_cat\"\n",
        "] = 1\n",
        "num_ticket.loc[\n",
        "    (num_ticket[\"Ticket\"] >= 200000) & (num_ticket[\"Ticket\"] < 300000), \"Ticket_cat\"\n",
        "] = 2\n",
        "num_ticket.loc[(num_ticket[\"Ticket\"] >= 300000), \"Ticket_cat\"] = 3\n",
        "\n",
        "num_alpha_ticket[\"Ticket_cat\"] = 4\n",
        "num_alpha_ticket.loc[num_alpha_ticket[\"Ticket\"].str.match(\"A.+\"), \"Ticket_cat\"] = 5\n",
        "num_alpha_ticket.loc[num_alpha_ticket[\"Ticket\"].str.match(\"C.+\"), \"Ticket_cat\"] = 6\n",
        "num_alpha_ticket.loc[\n",
        "    num_alpha_ticket[\"Ticket\"].str.match(\"C\\.*A\\.*.+\"), \"Ticket_cat\"\n",
        "] = 7\n",
        "num_alpha_ticket.loc[num_alpha_ticket[\"Ticket\"].str.match(\"F\\.C.+\"), \"Ticket_cat\"] = 8\n",
        "num_alpha_ticket.loc[num_alpha_ticket[\"Ticket\"].str.match(\"PC.+\"), \"Ticket_cat\"] = 9\n",
        "num_alpha_ticket.loc[num_alpha_ticket[\"Ticket\"].str.match(\"S\\.+.+\"), \"Ticket_cat\"] = 10\n",
        "num_alpha_ticket.loc[num_alpha_ticket[\"Ticket\"].str.match(\"SC.+\"), \"Ticket_cat\"] = 11\n",
        "num_alpha_ticket.loc[num_alpha_ticket[\"Ticket\"].str.match(\"SOTON.+\"), \"Ticket_cat\"] = 12\n",
        "num_alpha_ticket.loc[num_alpha_ticket[\"Ticket\"].str.match(\"STON.+\"), \"Ticket_cat\"] = 13\n",
        "num_alpha_ticket.loc[\n",
        "    num_alpha_ticket[\"Ticket\"].str.match(\"W\\.*/C.+\"), \"Ticket_cat\"\n",
        "] = 14\n",
        "\n",
        "df = pd.concat([num_ticket, num_alpha_ticket]).sort_values(\"PassengerId\")\n",
        "\n",
        "# Family\n",
        "df[\"Family\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
        "df[\"Alone\"] = df[\"Family\"].apply(lambda x: 1 if x == 1 else 0)\n",
        "df[\"Family_small\"] = df[\"Family\"].apply(lambda x: 1 if (2 <= x and x < 5) else 0)\n",
        "df[\"Family_middle\"] = df[\"Family\"].apply(lambda x: 1 if (5 <= x < 8) else 0)\n",
        "df[\"Family_big\"] = df[\"Family\"].apply(lambda x: 1 if (8 <= x) else 0)\n",
        "\n",
        "# Fare\n",
        "df[\"Fare\"] = df[\"Fare\"].fillna(df.query('Pclass==3 & Embarked==\"S\"')[\"Fare\"].median())\n",
        "\n",
        "filter_condition = (df[\"Pclass\"] == 1) & (df[\"Fare\"] == 0)\n",
        "filtered_data = df[filter_condition]\n",
        "pclass1_median_fare = df[df[\"Pclass\"] == 1][\"Fare\"].median()\n",
        "df.loc[filter_condition, \"Fare\"] = pclass1_median_fare\n",
        "filter_condition = (df[\"Pclass\"] == 2) & (df[\"Fare\"] == 0)\n",
        "filtered_data = df[filter_condition]\n",
        "pclass1_median_fare = df[df[\"Pclass\"] == 2][\"Fare\"].median()\n",
        "df.loc[filter_condition, \"Fare\"] = pclass1_median_fare\n",
        "filter_condition = (df[\"Pclass\"] == 3) & (df[\"Fare\"] == 0)\n",
        "filtered_data = df[filter_condition]\n",
        "pclass1_median_fare = df[df[\"Pclass\"] == 3][\"Fare\"].median()\n",
        "df.loc[filter_condition, \"Fare\"] = pclass1_median_fare\n",
        "df[\"Fare_cat\"] = pd.qcut(df[\"Fare\"], 4, labels=False)\n",
        "\n",
        "# Cabin\n",
        "df[\"Cabin\"].fillna(\"n\", inplace=True)\n",
        "df[\"Cabin\"] = df[\"Cabin\"].str[0]\n",
        "\n",
        "# Embarked\n",
        "df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
        "\n",
        "# ダミー化\n",
        "df = pd.get_dummies(\n",
        "    df,\n",
        "    columns=[\n",
        "        \"Sex\",\n",
        "        \"Pclass\",\n",
        "        \"Title\",\n",
        "        \"Ticket_cat\",\n",
        "        \"Fare_cat\",\n",
        "        \"Cabin\",\n",
        "        \"Embarked\",\n",
        "        \"Family_survival\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "# ドロップ\n",
        "df.drop([\"Name\", \"Last_name\", \"Ticket\", \"Cabin_T\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "43waZ47q4dZD"
      },
      "outputs": [],
      "source": [
        "df_predict = df[\n",
        "    [\n",
        "        \"Age\",\n",
        "        \"Alone\",\n",
        "        \"Family_small\",\n",
        "        \"Family_middle\",\n",
        "        \"Family_big\",\n",
        "        \"Sex_female\",\n",
        "        \"Sex_male\",\n",
        "        \"Pclass_1\",\n",
        "        \"Pclass_2\",\n",
        "        \"Pclass_3\",\n",
        "        \"Title_Master\",\n",
        "        \"Title_Miss\",\n",
        "        \"Title_Mr\",\n",
        "        \"Title_Mrs\",\n",
        "        \"Title_Rare\",\n",
        "        \"Ticket_cat_0\",\n",
        "        \"Ticket_cat_1\",\n",
        "        \"Ticket_cat_2\",\n",
        "        \"Ticket_cat_3\",\n",
        "        \"Ticket_cat_4\",\n",
        "        \"Ticket_cat_5\",\n",
        "        \"Ticket_cat_6\",\n",
        "        \"Ticket_cat_7\",\n",
        "        \"Ticket_cat_8\",\n",
        "        \"Ticket_cat_9\",\n",
        "        \"Ticket_cat_10\",\n",
        "        \"Ticket_cat_11\",\n",
        "        \"Ticket_cat_12\",\n",
        "        \"Ticket_cat_13\",\n",
        "        \"Ticket_cat_14\",\n",
        "        \"Fare_cat_0\",\n",
        "        \"Fare_cat_1\",\n",
        "        \"Fare_cat_2\",\n",
        "        \"Fare_cat_3\",\n",
        "        \"Cabin_A\",\n",
        "        \"Cabin_B\",\n",
        "        \"Cabin_C\",\n",
        "        \"Cabin_D\",\n",
        "        \"Cabin_E\",\n",
        "        \"Cabin_F\",\n",
        "        \"Cabin_G\",\n",
        "        \"Cabin_n\",\n",
        "        \"Embarked_C\",\n",
        "        \"Embarked_Q\",\n",
        "        \"Embarked_S\",\n",
        "    ]\n",
        "]\n",
        "known_age = df_predict[df_predict.Age.notnull()].values\n",
        "unknown_age = df_predict[df_predict.Age.isnull()].values\n",
        "\n",
        "X = known_age[:, 1:]\n",
        "y = known_age[:, 0]\n",
        "\n",
        "rfr = RandomForestRegressor(random_state=42, n_estimators=100, n_jobs=-1)\n",
        "rfr.fit(X, y)\n",
        "predictedAges = rfr.predict(unknown_age[:, 1::])\n",
        "\n",
        "df.loc[df.Age.isnull(), \"Age\"] = predictedAges\n",
        "df[\"Age_cat\"] = pd.qcut(df[\"Age\"], q=5, labels=False, precision=1)\n",
        "df = pd.get_dummies(df, columns=[\"Age_cat\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NR4oQUuOrpF4"
      },
      "outputs": [],
      "source": [
        "Sex_columns = [\"Sex_male\", \"Sex_female\"]\n",
        "Pclass_columns = [\"Pclass_1\", \"Pclass_2\", \"Pclass_3\"]\n",
        "Age_columns = [\"Age_cat_0\", \"Age_cat_1\", \"Age_cat_2\", \"Age_cat_3\", \"Age_cat_4\"]\n",
        "Family_columns = [\"Alone\", \"Family_small\", \"Family_middle\", \"Family_big\"]\n",
        "Survived_columns = [\"Survived_list\"]\n",
        "Dead_columns = [\"Dead_list\"]\n",
        "\n",
        "\n",
        "def AND(data_frame, columns_1, columns_2):\n",
        "    new_columns = {}\n",
        "    combinations = list(itertools.product(columns_1, columns_2))\n",
        "    for combo in combinations:\n",
        "        new_column_name = \" AND \".join(combo)\n",
        "        new_columns[new_column_name] = (\n",
        "            data_frame[combo[0]].fillna(0) & data_frame[combo[1]].fillna(0)\n",
        "        ).astype(int)\n",
        "    return pd.DataFrame(new_columns)\n",
        "\n",
        "\n",
        "df = pd.concat([df, AND(df, Sex_columns, Family_columns)], axis=1)\n",
        "df = pd.concat([df, AND(df, Pclass_columns, Sex_columns)], axis=1)\n",
        "df = pd.concat([df, AND(df, Age_columns, Sex_columns)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5OcDoQbGK3l",
        "outputId": "00cbbdba-d99b-48e9-f50a-9f70a48af9a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PassengerId', 'Survived', 'Age', 'SibSp', 'Parch', 'Fare', 'Surname', 'Dead_list', 'Survived_list', 'Family', 'Alone', 'Family_small', 'Family_middle', 'Family_big', 'Sex_female', 'Sex_male', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare', 'Ticket_cat_0', 'Ticket_cat_1', 'Ticket_cat_2', 'Ticket_cat_3', 'Ticket_cat_4', 'Ticket_cat_5', 'Ticket_cat_6', 'Ticket_cat_7', 'Ticket_cat_8', 'Ticket_cat_9', 'Ticket_cat_10', 'Ticket_cat_11', 'Ticket_cat_12', 'Ticket_cat_13', 'Ticket_cat_14', 'Fare_cat_0', 'Fare_cat_1', 'Fare_cat_2', 'Fare_cat_3', 'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_n', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Family_survival_0.0', 'Family_survival_0.5', 'Family_survival_1.0', 'Age_cat_0', 'Age_cat_1', 'Age_cat_2', 'Age_cat_3', 'Age_cat_4', 'Sex_male AND Alone', 'Sex_male AND Family_small', 'Sex_male AND Family_middle', 'Sex_male AND Family_big', 'Sex_female AND Alone', 'Sex_female AND Family_small', 'Sex_female AND Family_middle', 'Sex_female AND Family_big', 'Pclass_1 AND Sex_male', 'Pclass_1 AND Sex_female', 'Pclass_2 AND Sex_male', 'Pclass_2 AND Sex_female', 'Pclass_3 AND Sex_male', 'Pclass_3 AND Sex_female', 'Age_cat_0 AND Sex_male', 'Age_cat_0 AND Sex_female', 'Age_cat_1 AND Sex_male', 'Age_cat_1 AND Sex_female', 'Age_cat_2 AND Sex_male', 'Age_cat_2 AND Sex_female', 'Age_cat_3 AND Sex_male', 'Age_cat_3 AND Sex_female', 'Age_cat_4 AND Sex_male', 'Age_cat_4 AND Sex_female']\n"
          ]
        }
      ],
      "source": [
        "print(list(df.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYiIH8rrmXoE"
      },
      "source": [
        "### データ加工"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TyNXNkELmXUR"
      },
      "outputs": [],
      "source": [
        "df_predict = df[\n",
        "    [\n",
        "        \"Survived\",\n",
        "        \"Dead_list\",\n",
        "        \"Survived_list\",\n",
        "        \"Alone\",\n",
        "        \"Family_small\",\n",
        "        \"Family_middle\",\n",
        "        \"Family_big\",\n",
        "        \"Sex_female\",\n",
        "        \"Sex_male\",\n",
        "        \"Pclass_1\",\n",
        "        \"Pclass_2\",\n",
        "        \"Pclass_3\",\n",
        "        \"Ticket_cat_0\",\n",
        "        \"Ticket_cat_1\",\n",
        "        \"Ticket_cat_2\",\n",
        "        \"Ticket_cat_3\",\n",
        "        \"Ticket_cat_4\",\n",
        "        \"Ticket_cat_5\",\n",
        "        \"Ticket_cat_6\",\n",
        "        \"Ticket_cat_7\",\n",
        "        \"Ticket_cat_8\",\n",
        "        \"Ticket_cat_9\",\n",
        "        \"Ticket_cat_10\",\n",
        "        \"Ticket_cat_11\",\n",
        "        \"Ticket_cat_12\",\n",
        "        \"Ticket_cat_13\",\n",
        "        \"Ticket_cat_14\",\n",
        "        \"Cabin_A\",\n",
        "        \"Cabin_B\",\n",
        "        \"Cabin_C\",\n",
        "        \"Cabin_D\",\n",
        "        \"Cabin_E\",\n",
        "        \"Cabin_F\",\n",
        "        \"Cabin_G\",\n",
        "        \"Cabin_n\",\n",
        "        \"Family_survival_0.0\",\n",
        "        \"Family_survival_0.5\",\n",
        "        \"Family_survival_1.0\",\n",
        "        \"Age_cat_0\",\n",
        "        \"Age_cat_1\",\n",
        "        \"Age_cat_2\",\n",
        "        \"Age_cat_3\",\n",
        "        \"Age_cat_4\",\n",
        "        \"Sex_male AND Alone\",\n",
        "        \"Sex_male AND Family_small\",\n",
        "        \"Sex_male AND Family_middle\",\n",
        "        \"Sex_male AND Family_big\",\n",
        "        \"Sex_female AND Alone\",\n",
        "        \"Sex_female AND Family_small\",\n",
        "        \"Sex_female AND Family_middle\",\n",
        "        \"Sex_female AND Family_big\",\n",
        "        \"Pclass_1 AND Sex_male\",\n",
        "        \"Pclass_1 AND Sex_female\",\n",
        "        \"Pclass_2 AND Sex_male\",\n",
        "        \"Pclass_2 AND Sex_female\",\n",
        "        \"Pclass_3 AND Sex_male\",\n",
        "        \"Pclass_3 AND Sex_female\",\n",
        "        \"Age_cat_0 AND Sex_male\",\n",
        "        \"Age_cat_0 AND Sex_female\",\n",
        "        \"Age_cat_1 AND Sex_male\",\n",
        "        \"Age_cat_1 AND Sex_female\",\n",
        "        \"Age_cat_2 AND Sex_male\",\n",
        "        \"Age_cat_2 AND Sex_female\",\n",
        "        \"Age_cat_3 AND Sex_male\",\n",
        "        \"Age_cat_3 AND Sex_female\",\n",
        "        \"Age_cat_4 AND Sex_male\",\n",
        "        \"Age_cat_4 AND Sex_female\",\n",
        "    ]\n",
        "]\n",
        "train = df_predict.iloc[:df_train_len]\n",
        "test = df_predict.iloc[df_train_len:]\n",
        "X_train = train.drop([\"Survived\"], axis=1)\n",
        "y_train = train[\"Survived\"]\n",
        "X_test = test.drop([\"Survived\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeoyWiRl357l"
      },
      "source": [
        "### ランダムフォレスト"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\"max_depth\": [6], \"min_samples_leaf\": [1, 2, 4]}\n",
        "\n",
        "rfc_gs = GridSearchCV(\n",
        "    RandomForestClassifier(n_estimators=100, criterion=\"entropy\", n_jobs=-1, random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        ")\n",
        "rfc_gs.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters: {}\".format(rfc_gs.best_params_))\n",
        "print(\"CV Score: {}\".format(round(rfc_gs.best_score_, 3)))\n",
        "rfc_pred = rfc_gs.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mxmi2rdeGlm",
        "outputId": "edf2a4eb-f043-411c-a666-0fd8bbfe8cb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 6, 'min_samples_leaf': 4}\n",
            "CV Score: 0.864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5HVuc1-dErqh"
      },
      "outputs": [],
      "source": [
        "df_test[\"Survived\"] = np.where(rfc_pred >= 0.42, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dwxHmyGySfsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c969ec11-5d0e-4add-839c-13b3e9b8b7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "print(list(df_test[\"Survived\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-JsgnojxXq_"
      },
      "source": [
        "### 提出ファイル作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UBrN9bIwxb9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "214b1a04-62df-4bda-9ab2-fa923fec0e84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dfe007c3-b7af-401f-bdaa-6759b688b063\", \"submission.csv\", 2839)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "submission = df_test[[\"PassengerId\", \"Survived\"]]\n",
        "submission.to_csv(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Titanic/submission.csv\",\n",
        "    index=False,\n",
        ")\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Titanic/submission.csv\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}